{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae83b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, length, countDistinct\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdd4187",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) â€” Intro Section\n",
    "\n",
    "The dataset under study has already been preprocessed into **chunked texts** of 300â€“500 characters, \n",
    "resulting in a large corpus suitable for modeling. To handle the heavy dataset efficiently \n",
    "(~2.9 million records), we use **PySpark** for data extraction and summarization.\n",
    "\n",
    "In this introductory stage of EDA, our goals are:\n",
    "- Describe the **basic shape** of the dataset (total chunk records).\n",
    "- Count the number of **unique authors** and **unique titles** in the corpus.\n",
    "- Explore **genre distribution**, with a special focus on \"Fantasy\" records.\n",
    "- Provide a few **interesting facts** about the corpus to set the stage for deeper visual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61f2b192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Dataset Overview\n",
      "Total chunked records: 2,930,008\n",
      "Unique authors: 142\n",
      "Unique titles: 3022\n",
      "\n",
      "Genre distribution (top 10):\n",
      "+---------------------------------+------+\n",
      "|genre                            |count |\n",
      "+---------------------------------+------+\n",
      "|Literature/Novel, Fiction        |476896|\n",
      "|Historical/Adventure, Fiction    |211553|\n",
      "|Adventure/Novel, Fiction         |99022 |\n",
      "|Historical/Novel, Fiction        |93572 |\n",
      "|Unknown                          |73171 |\n",
      "|Adventure/Sea, Fiction           |71090 |\n",
      "|Literature/Collection, Fiction   |61501 |\n",
      "|Poetry, Fiction                  |59534 |\n",
      "|Literature/Short Stories, Fiction|58519 |\n",
      "|Young Adult/Adventure, Fiction   |52381 |\n",
      "+---------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Number of Fantasy-related chunks: 76,920\n",
      "Number of unique Fantasy authors: 25\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, length, countDistinct\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"AuthorEDA\").getOrCreate()\n",
    "\n",
    "# Load the full chunked dataset (~2.9M rows)\n",
    "df = spark.read.csv(\"dataset_splits/full_chunked.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# --- Basic Stats ---\n",
    "total_records = df.count()\n",
    "unique_authors = df.select(\"author\").distinct().count()\n",
    "unique_titles = df.select(\"title\").distinct().count()\n",
    "\n",
    "print(f\"ðŸ“Š Dataset Overview\")\n",
    "print(f\"Total chunked records: {total_records:,}\")\n",
    "print(f\"Unique authors: {unique_authors}\")\n",
    "print(f\"Unique titles: {unique_titles}\")\n",
    "\n",
    "# --- Genres ---\n",
    "genre_counts = df.groupBy(\"genre\").count().orderBy(col(\"count\").desc())\n",
    "print(\"\\nGenre distribution (top 10):\")\n",
    "genre_counts.show(10, truncate=False)\n",
    "\n",
    "# --- Fantasy Records ---\n",
    "fantasy_df = df.filter(col(\"genre\").like(\"%Fantasy%\"))\n",
    "fantasy_records = fantasy_df.count()\n",
    "fantasy_authors = fantasy_df.select(\"author\").distinct().count()\n",
    "\n",
    "print(f\"\\nNumber of Fantasy-related chunks: {fantasy_records:,}\")\n",
    "print(f\"Number of unique Fantasy authors: {fantasy_authors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9c588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
